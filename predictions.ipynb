{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from api import DataAPI\n",
    "api = DataAPI()\n",
    "\n",
    "'''\n",
    "Function: loads game statistics for a specified player and calculates trailing window statistics for specific features.\n",
    "It also constructs a feature set X and a target y based on a specified target column and rolling windows. \n",
    "The function then filters out columns with excessive missing values and short datasets.\n",
    " \n",
    "Returns: features X, target y, and the latest feature values\n",
    "'''\n",
    "\n",
    "def load_player_data(player, target, windows=[1, 3, 5, 10, 20], nan_thresh=.9, data_thresh=100):\n",
    "    try:\n",
    "        player_df = api.get_player_data(player)\n",
    "    except:\n",
    "        return None, None, None\n",
    "    player_df = player_df.reset_index(drop=False)\n",
    "    target_col = f'{target}_shift'\n",
    "\n",
    "    feature_df = pd.DataFrame()\n",
    "    for window in windows:\n",
    "        for feature in player_df.columns:\n",
    "            if feature in ['date', 'opponent', 'team']:\n",
    "                continue\n",
    "            feature_df[f'trailing_{window}_game_{feature}_mean'] = player_df[feature].rolling(window).mean()\n",
    "            feature_df[f'trailing_{window}_game_{feature}_std']  = player_df[feature].rolling(window).std()\n",
    "            feature_df[f'trailing_{window}_game_{feature}_min']  = player_df[feature].rolling(window).min()\n",
    "            feature_df[f'trailing_{window}_game_{feature}_max']  = player_df[feature].rolling(window).max()\n",
    "\n",
    "    feature_df = feature_df.dropna(thresh=int(len(feature_df) * nan_thresh), axis=1)\n",
    "    latest_features = feature_df.iloc[-1]\n",
    "\n",
    "    feature_df[target_col]= player_df[target].shift(max(windows))\n",
    "    feature_df = feature_df.dropna()\n",
    "\n",
    "    X = feature_df.drop(target_col, axis=1)\n",
    "    y = feature_df[target_col]\n",
    "\n",
    "    if len(X) < data_thresh:\n",
    "        return None, None, None\n",
    "\n",
    "    return X, y, latest_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "'''\n",
    "Function: Standardizes the features X, creates a binary target y_class based on a threshold value\n",
    "Returns: best estimator using grid search and the scaler.\n",
    "'''\n",
    "def train_player_model(X, y, value, model, param_grid, n_splits=10, test_size=5):\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits, gap=0, max_train_size=None, test_size=test_size)\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    y_class = y > value\n",
    "    grid = GridSearchCV(model, param_grid=param_grid, cv=tscv)\n",
    "    grid.fit(X, y_class)\n",
    "    return grid.best_estimator_, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "I set up hyperparameter grids for LogisticRegression and RandomForestClassifier\n",
    "Function: predict_player predicts the probability of a player's performance exceeding a specified threshold (line). \n",
    "The function utilizes the load_player_data function to generate features and targets,\n",
    "and then trains the models using train_player_model with cross-validation and grid search. \n",
    "Returns: results of both models \n",
    "'''\n",
    "\n",
    "logistic = LogisticRegression()\n",
    "logistic_param_grid = { \n",
    "    'C': [0.001, 0.01, 0.1],\n",
    "    'penalty': ['l2', 'l1'],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "\n",
    "random_forest = RandomForestClassifier()\n",
    "random_forest_param_grid = { \n",
    "    'n_estimators': [200],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [5],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "\n",
    "def predict_player(player, type, line):\n",
    "    X, y, latest = load_player_data(player, type)\n",
    "\n",
    "    if X is None:\n",
    "        return None, None\n",
    "\n",
    "    logistic_model, scaler = train_player_model(X, y, line, logistic, logistic_param_grid)\n",
    "    random_forest_model, scaler = train_player_model(X, y, line, random_forest, random_forest_param_grid)\n",
    "\n",
    "    latest = scaler.transform(latest.values.reshape(1, -1))\n",
    "    logistic_prediction = logistic_model.predict_proba(latest)\n",
    "    random_forest_prediction = random_forest_model.predict_proba(latest)\n",
    "\n",
    "    return logistic_prediction[0], random_forest_prediction[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts betting odds into implied probabilities \n",
    "def get_implied_prob(odds):\n",
    "    if odds < 0:\n",
    "        return abs(odds) / (abs(odds) + 100)\n",
    "    else:\n",
    "        return 100 / (odds + 100)\n",
    "    \n",
    "# calculates the expected value (EV) of a bet based on given odds and probability.\n",
    "def get_EV(odds, prob):\n",
    "    if odds < 0:\n",
    "        return prob * (100 / (abs(odds))) - (1 - prob)\n",
    "    else:\n",
    "        return prob * (odds / 100) - (1 - prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de'anthony melton\n",
      "isaiah stewart\n",
      "joel embiid\n",
      "kelly oubre jr.\n",
      "killian hayes\n",
      "tobias harris\n",
      "tyrese maxey\n",
      "corey kispert\n",
      "daniel gafford\n",
      "danilo gallinari\n",
      "deni avdija\n",
      "gordon hayward\n",
      "jordan poole\n",
      "kyle kuzma\n",
      "lamelo ball\n",
      "nick richards\n",
      "p.j. washington\n",
      "theo maledon\n",
      "tyus jones\n",
      "derrick white\n",
      "dorian finney-smith\n",
      "jaylen brown\n",
      "jayson tatum\n",
      "jrue holiday\n",
      "kristaps porzingis\n",
      "mikal bridges\n",
      "royce o'neale\n",
      "sam hauser\n",
      "spencer dinwiddie\n",
      "anthony edwards\n",
      "jaden mcdaniels\n",
      "karl-anthony towns\n",
      "keldon johnson\n",
      "kyle anderson\n",
      "mike conley\n",
      "naz reid\n",
      "rudy gobert\n",
      "collin sexton\n",
      "desmond bane\n",
      "jaren jackson jr.\n",
      "john collins\n",
      "jordan clarkson\n",
      "lauri markkanen\n",
      "marcus smart\n",
      "ziaire williams\n",
      "alperen sengun\n",
      "brandon ingram\n",
      "dillon brooks\n",
      "herbert jones\n",
      "jalen green\n",
      "jonas valanciunas\n",
      "grant williams\n",
      "ivica zubac\n",
      "james harden\n",
      "kawhi leonard\n",
      "kyrie irving\n",
      "luka doncic\n",
      "norman powell\n",
      "paul george\n",
      "russell westbrook\n",
      "tim hardaway jr.\n",
      "anthony davis\n",
      "austin reaves\n",
      "bradley beal\n",
      "christian wood\n",
      "d'angelo russell\n",
      "eric gordon\n",
      "grayson allen\n",
      "jusuf nurkic\n",
      "keita bates-diop\n",
      "kevin durant\n",
      "lebron james\n",
      "rui hachimura\n",
      "taurean prince\n",
      "domantas sabonis\n",
      "harrison barnes\n",
      "josh giddey\n",
      "kevin huerter\n",
      "malik monk\n",
      "shai gilgeous-alexander\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "'''\n",
    "Function: loads player betting lines from a JSON file for a specified date and type and calculates probabilities for whether \n",
    "the player will score over or under the given line. \n",
    "The probabilities are used to calculate implied probabilities and expected values (EVs) for betting on either side. \n",
    "Results: The results are stored in a list of dictionaries, (converted to a df and csv)\n",
    "'''\n",
    "date = '2023-11-10'\n",
    "type = 'points'\n",
    "line_type = 'pts'\n",
    "\n",
    "with open(f'../realtime/dates/{date}/{type}.json', 'r') as f:\n",
    "    lines = json.load(f)\n",
    "\n",
    "bet_df = []\n",
    "\n",
    "for player in list(lines.keys()):\n",
    "    line = lines[player]['line']\n",
    "    over_odds = lines[player]['over_odds']\n",
    "    under_odds = lines[player]['under_odds']\n",
    "    player = player.lower()\n",
    "    try:\n",
    "        log_proba, rf_proba = predict_player(player, line_type, line)\n",
    "        if log_proba is None:\n",
    "            continue\n",
    "    except:\n",
    "        continue\n",
    "    log_under_proba, log_over_proba = log_proba\n",
    "    rf_under_proba, rf_over_proba = rf_proba\n",
    "\n",
    "    over_implied_prob = get_implied_prob(over_odds)\n",
    "    under_implied_prob = get_implied_prob(under_odds)\n",
    "\n",
    "    over_EV = get_EV(over_odds, log_over_proba)\n",
    "    under_EV = get_EV(under_odds, log_under_proba)\n",
    "\n",
    "    print(player)\n",
    "\n",
    "    bet_df.append({\n",
    "        'player': player,\n",
    "        'market': type,\n",
    "        'line': line,\n",
    "        'over_odds': over_odds,\n",
    "        'under_odds': under_odds,\n",
    "        'over_implied_prob': over_implied_prob,\n",
    "        'under_implied_prob': under_implied_prob,\n",
    "        'over_EV': over_EV,\n",
    "        'under_EV': under_EV,\n",
    "        'log_over_proba': log_over_proba,\n",
    "        'log_under_proba': log_under_proba,\n",
    "        'rf_over_proba': rf_over_proba,\n",
    "        'rf_under_proba': rf_under_proba,\n",
    "    })\n",
    "\n",
    "bet_df = pd.DataFrame(bet_df)\n",
    "bet_df = bet_df.to_csv('bet_df.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0 (v3.10.0:b494f5935c, Oct  4 2021, 14:59:19) [Clang 12.0.5 (clang-1205.0.22.11)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e1998ff7f8aa20ada591c520b972326324e5ea05489af9e422744c7c09f6dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
